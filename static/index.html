<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Genevieve â€” AI Learning Advisor</title>
  <style>
    *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

    body {
      font-family: 'Segoe UI', Arial, sans-serif;
      background: #0f0f1a;
      color: #e8e8f0;
      height: 100vh;
      display: flex;
      flex-direction: column;
      overflow: hidden;
    }

    header {
      display: flex;
      align-items: center;
      gap: 12px;
      padding: 12px 24px;
      background: #1a1a2e;
      border-bottom: 1px solid #2a2a4a;
      flex-shrink: 0;
    }
    #status-dot {
      width: 10px; height: 10px; border-radius: 50%;
      background: #ef4444; flex-shrink: 0; transition: background .3s;
    }
    #status-dot.connected { background: #22c55e; }
    header h1 { font-size: 1.05rem; font-weight: 700; color: #a78bfa; }
    header p  { font-size: .75rem; color: #666; margin-top: 1px; }

    main { flex: 1; display: flex; overflow: hidden; }

    /* â”€â”€ Avatar panel â”€â”€ */
    #avatar-panel {
      width: 300px; flex-shrink: 0;
      background: #10102a;
      display: flex; flex-direction: column;
      align-items: center; justify-content: center;
      padding: 20px 12px;
      border-right: 1px solid #2a2a4a;
      gap: 14px;
    }
    #avatar-ring {
      position: relative;
      width: 220px; height: 220px;
      border-radius: 50%;
      border: 3px solid #7c3aed;
      box-shadow: 0 0 28px rgba(124,58,237,.45), 0 0 60px rgba(124,58,237,.15);
      overflow: hidden;
      flex-shrink: 0;
    }
    /* Avatar canvas â€” pre-baked viseme sprite is drawn here each frame */
    #avatar-canvas {
      position: absolute; top: 0; left: 0;
      width: 220px; height: 220px; display: block;
    }
    #avatar-name { font-size: 1rem; font-weight: 700; color: #c4b5fd; letter-spacing: .06em; }
    #avatar-status {
      font-size: .75rem; color: #666; min-height: 1em; transition: color .3s;
    }
    #avatar-status.speaking  { color: #22c55e; }
    #avatar-status.thinking  { color: #f59e0b; }
    #avatar-status.listening { color: #38bdf8; }

    /* â”€â”€ Chat panel â”€â”€ */
    #chat-panel { flex: 1; display: flex; flex-direction: column; overflow: hidden; }
    #chat-log {
      flex: 1; overflow-y: auto;
      padding: 18px; display: flex; flex-direction: column; gap: 10px;
    }
    #chat-log::-webkit-scrollbar { width: 4px; }
    #chat-log::-webkit-scrollbar-thumb { background: #3a3a5a; border-radius: 4px; }

    .bubble {
      max-width: 80%; padding: 9px 13px;
      border-radius: 16px; font-size: .88rem; line-height: 1.5;
    }
    .bubble.user {
      align-self: flex-end; background: #4c1d95; color: #f0e8ff;
      border-bottom-right-radius: 4px;
    }
    .bubble.bot {
      align-self: flex-start; background: #1e1e3a; color: #e2e2f0;
      border: 1px solid #2e2e5a; border-bottom-left-radius: 4px;
    }
    .bubble .lbl { font-size: .68rem; font-weight: 700; opacity: .6; margin-bottom: 3px; letter-spacing: .05em; }

    .dots span {
      display: inline-block; width: 6px; height: 6px; border-radius: 50%;
      background: #7c3aed; margin: 0 2px; animation: bounce 1.1s infinite;
    }
    .dots span:nth-child(2) { animation-delay: .18s; }
    .dots span:nth-child(3) { animation-delay: .36s; }
    @keyframes bounce {
      0%,80%,100% { transform: translateY(0); opacity: .35; }
      40%          { transform: translateY(-7px); opacity: 1; }
    }

    .courses-section { align-self: flex-start; max-width: 90%; }
    .courses-hdr { font-size: .72rem; font-weight: 700; color: #a78bfa; margin-bottom: 8px; letter-spacing: .05em; }
    .card {
      background: #1a1a35; border: 1px solid #3a2a6a;
      border-radius: 11px; padding: 11px 13px; margin-bottom: 7px;
    }
    .card .ct { font-weight: 600; font-size: .88rem; color: #c4b5fd; margin-bottom: 3px; }
    .card .cm { font-size: .73rem; color: #777; margin-bottom: 5px; }
    .card .cr { font-size: .76rem; color: #999; font-style: italic; }
    .badge {
      display: inline-block; padding: 1px 7px; border-radius: 10px;
      font-size: .65rem; font-weight: 700; text-transform: uppercase; margin-right: 5px;
    }
    .badge.beginner     { background: #14532d; color: #86efac; }
    .badge.intermediate { background: #713f12; color: #fde68a; }
    .badge.advanced     { background: #450a0a; color: #fca5a5; }

    #input-bar {
      padding: 12px 18px; background: #14142a;
      border-top: 1px solid #2a2a4a;
      display: flex; gap: 8px; align-items: center; flex-shrink: 0;
    }
    #text-input {
      flex: 1; padding: 9px 14px;
      background: #1e1e38; border: 1px solid #3a3a60;
      border-radius: 22px; color: #e8e8f0; font-size: .88rem;
      outline: none; transition: border-color .2s;
    }
    #text-input:focus { border-color: #7c3aed; }
    #text-input::placeholder { color: #444; }
    .btn {
      width: 40px; height: 40px; border: none; border-radius: 50%;
      cursor: pointer; font-size: 1.05rem;
      display: flex; align-items: center; justify-content: center;
      transition: transform .1s, background .2s; flex-shrink: 0;
    }
    .btn:active { transform: scale(.9); }
    #send-btn { background: #7c3aed; color: #fff; }
    #send-btn:hover { background: #6d28d9; }
    #record-btn { background: #1e1e38; color: #ccc; border: 1px solid #3a3a60; }
    #record-btn:hover { background: #2a2a50; }
    #record-btn.recording {
      background: #dc2626; color: #fff; border-color: transparent;
      animation: rpulse 1s infinite;
    }
    @keyframes rpulse {
      0%,100% { box-shadow: 0 0 0 0 rgba(220,38,38,.5); }
      50%      { box-shadow: 0 0 0 8px rgba(220,38,38,0); }
    }
  </style>
</head>
<body>

<header>
  <div id="status-dot"></div>
  <div>
    <h1>Genevieve â€” AI Learning Advisor</h1>
    <p>Fully local &bull; gemma3:4b &bull; Whisper STT &bull; Edge TTS</p>
  </div>
</header>

<main>
  <div id="avatar-panel">
    <div id="avatar-ring">
      <!-- Single canvas: pre-baked viseme sprites swapped each frame -->
      <canvas id="avatar-canvas" width="220" height="220"></canvas>
      <!-- Neural talking loop: plays muted while TTS audio runs (viseme mode) -->
      <video id="talking-vid" loop muted playsinline preload="auto"
        style="position:absolute;top:0;left:0;width:220px;height:220px;
               object-fit:cover;object-position:50% 15%;
               border-radius:50%;z-index:5;display:none;">
        <source src="/static/videos/talking_loop.mp4" type="video/mp4">
      </video>
    </div>
    <div id="avatar-name">GENEVIEVE</div>
    <div id="avatar-status">Loadingâ€¦</div>
  </div>

  <div id="chat-panel">
    <div id="chat-log"></div>
    <div id="input-bar">
      <input id="text-input" type="text" placeholder="Type a messageâ€¦" autocomplete="off"/>
      <button id="send-btn"   class="btn" title="Send">&#9658;</button>
      <button id="record-btn" class="btn" title="Record voice">&#127908;</button>
    </div>
  </div>
</main>

<script>
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//  AVATAR â€” VISEME SPRITE SWAP
//  Six sprites (v0.jpg â€¦ v5.jpg) are pre-baked at server startup.
//  mouthLoop cross-fades between adjacent sprites based on audio
//  amplitude so the mouth opens/closes smoothly in real time.
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
const CW = 220, CH = 220;
const avatarCanvas = document.getElementById('avatar-canvas');
const avatarCtx    = avatarCanvas.getContext('2d');

// Preload all viseme sprites (generated by server before first request)
const NUM_SPRITES = 6;
const sprites = Array.from({ length: NUM_SPRITES }, (_, i) => {
  const img = new Image();
  img.src = `/static/images/visemes/v${i}.jpg`;
  return img;
});

// Smooth mouth animation state (also written by the audio section)
let mouthTarget  = 0;
let mouthCurrent = 0;

// â”€â”€ Avatar init â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function initAvatar() {
  const base = sprites[0];
  if (base.complete && base.naturalWidth > 0) {
    avatarCtx.drawImage(base, 0, 0, CW, CH);
    requestAnimationFrame(mouthLoop);
  } else {
    base.onload = () => {
      avatarCtx.drawImage(base, 0, 0, CW, CH);
      requestAnimationFrame(mouthLoop);
    };
    base.onerror = () => setStatus('', 'Sprites missing â€” restart server.');
  }
}

// â”€â”€ Mouth animation loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function mouthLoop() {
  // Ease toward target amplitude
  mouthCurrent += (mouthTarget - mouthCurrent) * 0.18;

  // Map 0â€“1 amplitude to sprite index 0â€“5 with linear interpolation
  const exactIdx = Math.max(0, Math.min(NUM_SPRITES - 1, mouthCurrent * (NUM_SPRITES - 1)));
  const lo   = Math.floor(exactIdx);
  const hi   = Math.min(NUM_SPRITES - 1, lo + 1);
  const frac = exactIdx - lo;

  const sLo = sprites[lo];
  const sHi = sprites[hi];

  if (sLo.complete && sLo.naturalWidth > 0) {
    // Draw base sprite
    avatarCtx.globalAlpha = 1;
    avatarCtx.drawImage(sLo, 0, 0, CW, CH);

    // Cross-fade to next sprite for sub-step smoothness
    if (frac > 0.01 && hi !== lo && sHi.complete && sHi.naturalWidth > 0) {
      avatarCtx.globalAlpha = frac;
      avatarCtx.drawImage(sHi, 0, 0, CW, CH);
      avatarCtx.globalAlpha = 1;
    }
  }

  requestAnimationFrame(mouthLoop);
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//  AUDIO PLAYBACK + LIP SYNC
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
let audioCtx = null, analyser = null, activeSource = null, lipRaf = null;

// Resolved by the first user gesture so queued audio can play immediately.
let _audioUnlocked = false;
let _unlockResolvers = [];
function _audioUnlockedPromise() {
  if (_audioUnlocked) return Promise.resolve();
  return new Promise(res => _unlockResolvers.push(res));
}

// Call this synchronously inside every user-gesture handler.
// Creates the AudioContext (or resumes it) while the browser still trusts
// the call stack as a user-initiated action.
function _unlockAudio() {
  if (_audioUnlocked) return;
  if (!audioCtx) audioCtx = new (window.AudioContext || window.webkitAudioContext)();
  const p = audioCtx.state !== 'running' ? audioCtx.resume() : Promise.resolve();
  p.then(() => {
    _audioUnlocked = true;
    _unlockResolvers.forEach(r => r());
    _unlockResolvers = [];
  });
}

// Neural talking-loop video element (viseme mode only)
const talkingVid = document.getElementById('talking-vid');
const loopReady  = talkingVid && talkingVid.querySelector('source');

function _startTalkingLoop() {
  if (!loopReady) return;
  talkingVid.currentTime = 0;
  talkingVid.playbackRate = 1.0;
  talkingVid.style.display = 'block';
  talkingVid.play().catch(() => {});
}

function _stopTalkingLoop() {
  if (!loopReady) return;
  talkingVid.pause();
  talkingVid.style.display = 'none';
}

function playAudioWithLipSync(base64Audio) {
  if (activeSource) { try { activeSource.stop(); } catch(e){} activeSource = null; }
  if (lipRaf) { cancelAnimationFrame(lipRaf); lipRaf = null; }

  const bytes = Uint8Array.from(atob(base64Audio), c => c.charCodeAt(0));

  // Wait until the AudioContext has been unlocked by a user gesture.
  // Greeting audio queues here and plays the moment the user first
  // clicks or presses Enter â€” no audio is silently dropped.
  _audioUnlockedPromise().then(() => {
    audioCtx.decodeAudioData(bytes.buffer.slice(0), buffer => {
      setStatus('speaking', 'Speakingâ€¦');
      activeSource = audioCtx.createBufferSource();
      activeSource.buffer = buffer;

      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 512;
      const freqData = new Uint8Array(analyser.frequencyBinCount);

      activeSource.connect(analyser);
      analyser.connect(audioCtx.destination);
      activeSource.start();

      _startTalkingLoop();

      const nyquist  = audioCtx.sampleRate / 2;
      const binHz    = nyquist / analyser.frequencyBinCount;
      const loIdx    = Math.floor(300  / binHz);
      const hiIdx    = Math.floor(3000 / binHz);

      function lipLoop() {
        analyser.getByteFrequencyData(freqData);
        let sum = 0;
        for (let i = loIdx; i <= hiIdx; i++) sum += freqData[i];
        const avg = sum / (hiIdx - loIdx + 1) / 255;
        mouthTarget = Math.min(1, avg * 3.5);

        if (loopReady && !talkingVid.paused) {
          talkingVid.playbackRate = Math.max(0.6, Math.min(1.5, 0.6 + mouthTarget * 1.5));
        }

        lipRaf = requestAnimationFrame(lipLoop);
      }
      lipLoop();

      activeSource.onended = () => {
        cancelAnimationFrame(lipRaf); lipRaf = null;
        activeSource = null;
        mouthTarget = 0;
        _stopTalkingLoop();
        setStatus('connected', 'Listeningâ€¦');
      };
    }, err => {
      console.error('Audio decode:', err);
      mouthTarget = 0;
      _stopTalkingLoop();
      setStatus('connected', 'Ready');
    });
  });
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//  WEBSOCKET
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
let ws;
function connect() {
  const proto = location.protocol === 'https:' ? 'wss' : 'ws';
  ws = new WebSocket(`${proto}://${location.host}/api/v1/ws`);
  ws.onopen  = () => {
    document.getElementById('status-dot').classList.add('connected');
    setStatus('connected', 'Connected');
  };
  ws.onmessage = evt => {
    const msg = JSON.parse(evt.data);
    if (msg.type === 'response') {
      removeThinking();
      appendBot(msg.text);

      if (msg.video) {
        // â”€â”€ MuseTalk path: play lip-synced video inside the avatar ring â”€â”€
        const bytes = Uint8Array.from(atob(msg.video), c => c.charCodeAt(0));
        const blob  = new Blob([bytes], { type: 'video/mp4' });
        const url   = URL.createObjectURL(blob);
        const vid   = document.createElement('video');
        vid.src      = url;
        vid.autoplay = true;
        vid.style.cssText =
          'position:absolute;top:0;left:0;width:220px;height:220px;' +
          'object-fit:cover;border-radius:50%;z-index:10;';
        const ring = document.getElementById('avatar-ring');
        ring.appendChild(vid);
        setStatus('speaking', 'Speaking');
        vid.onended = () => {
          ring.removeChild(vid);
          URL.revokeObjectURL(url);
          setStatus('connected', 'Ready');
        };

      } else if (msg.audio) {
        // â”€â”€ Viseme path: unchanged â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        playAudioWithLipSync(msg.audio);
      }
    }
    if (msg.type === 'recommendations') showCourses(msg.courses);
  };
  ws.onclose = () => {
    document.getElementById('status-dot').classList.remove('connected');
    setStatus('', 'Reconnectingâ€¦');
    setTimeout(connect, 2000);
  };
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//  UI HELPERS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
function setStatus(cls, text) {
  const el = document.getElementById('avatar-status');
  el.className = cls; el.textContent = text;
}

const chatLog = document.getElementById('chat-log');

function appendUser(text) {
  const d = document.createElement('div');
  d.className = 'bubble user';
  d.innerHTML = `<div class="lbl">YOU</div>${esc(text)}`;
  chatLog.appendChild(d); chatLog.scrollTop = chatLog.scrollHeight;
}
function appendBot(text) {
  const d = document.createElement('div');
  d.className = 'bubble bot';
  d.innerHTML = `<div class="lbl">GENEVIEVE</div>${esc(text)}`;
  chatLog.appendChild(d); chatLog.scrollTop = chatLog.scrollHeight;
}
function showThinking() {
  const d = document.createElement('div');
  d.className = 'bubble bot'; d.id = 'thinking';
  d.innerHTML = `<div class="lbl">GENEVIEVE</div>
    <span class="dots"><span></span><span></span><span></span></span>`;
  chatLog.appendChild(d); chatLog.scrollTop = chatLog.scrollHeight;
  setStatus('thinking', 'Thinkingâ€¦');
}
function removeThinking() { document.getElementById('thinking')?.remove(); }

function showCourses(courses) {
  const sec = document.createElement('div');
  sec.className = 'courses-section';
  sec.innerHTML = `<div class="courses-hdr">RECOMMENDED COURSES</div>`;
  courses.forEach(c => {
    const card = document.createElement('div');
    card.className = 'card';
    card.innerHTML = `
      <div class="ct">${esc(c.title)}</div>
      <div class="cm">
        <span class="badge ${c.level||''}">${c.level||''}</span>
        ${esc(c.provider)} &bull; ${esc(c.duration)} &bull; &#9733; ${c.rating}
      </div>
      <div class="cr">${esc(c.reason||'')}</div>`;
    sec.appendChild(card);
  });
  chatLog.appendChild(sec); chatLog.scrollTop = chatLog.scrollHeight;
}

function esc(s) {
  return String(s??'')
    .replace(/&/g,'&amp;').replace(/</g,'&lt;').replace(/>/g,'&gt;');
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//  TEXT INPUT
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
function sendText() {
  const inp = document.getElementById('text-input');
  const text = inp.value.trim();
  if (!text || !ws || ws.readyState !== WebSocket.OPEN) return;
  _unlockAudio();   // unlock AudioContext synchronously inside this gesture
  appendUser(text);
  ws.send(JSON.stringify({ type: 'text', text }));
  inp.value = '';
  showThinking();
}
document.getElementById('send-btn').addEventListener('click', sendText);
document.getElementById('text-input').addEventListener('keydown', e => {
  if (e.key === 'Enter' && !e.shiftKey) { e.preventDefault(); sendText(); }
});

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//  MIC RECORDING
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
let mediaRecorder = null, audioChunks = [], isRecording = false;
const recBtn = document.getElementById('record-btn');

function getBestMime() {
  const types = [
    'audio/webm;codecs=opus', 'audio/webm',
    'audio/ogg;codecs=opus',  'audio/mp4',
  ];
  return types.find(t => MediaRecorder.isTypeSupported(t)) || '';
}

recBtn.addEventListener('click', async () => {
  _unlockAudio();   // unlock AudioContext synchronously inside this gesture
  if (isRecording) {
    mediaRecorder.stop();
    isRecording = false;
    recBtn.classList.remove('recording');
    recBtn.innerHTML = '&#127908;';
    recBtn.title = 'Record voice';
    return;
  }
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
    audioChunks = [];
    const mime = getBestMime();
    const opts = mime ? { mimeType: mime } : {};
    mediaRecorder = new MediaRecorder(stream, opts);
    const usedMime = mediaRecorder.mimeType || mime || 'audio/webm';

    mediaRecorder.ondataavailable = e => { if (e.data.size > 0) audioChunks.push(e.data); };
    mediaRecorder.onstop = () => {
      stream.getTracks().forEach(t => t.stop());
      const blob   = new Blob(audioChunks, { type: usedMime });
      audioChunks  = [];
      const reader = new FileReader();
      reader.onloadend = () => {
        const b64 = reader.result.split(',')[1];
        appendUser('ğŸ¤ [Voice message]');
        ws.send(JSON.stringify({ type: 'audio', audio: b64, mime: usedMime }));
        showThinking();
        setStatus('thinking', 'Transcribingâ€¦');
      };
      reader.readAsDataURL(blob);
    };

    mediaRecorder.start(250);
    isRecording = true;
    recBtn.classList.add('recording');
    recBtn.innerHTML = '&#9632;';
    recBtn.title = 'Stop recording';
    setStatus('listening', 'Listeningâ€¦');

  } catch (err) {
    console.error('Mic error:', err);
    alert(`Microphone error: ${err.message}\n\nPlease allow microphone access and reload.`);
  }
});

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//  BOOT
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
initAvatar();   // load v0 sprite and start mouthLoop
connect();      // open WebSocket
</script>
</body>
</html>
